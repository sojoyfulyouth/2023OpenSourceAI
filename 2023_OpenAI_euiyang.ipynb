{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"agsW9_PhbUEp","executionInfo":{"status":"ok","timestamp":1703145577570,"user_tz":-540,"elapsed":17996,"user":{"displayName":"정의양","userId":"12576123445162133975"}},"outputId":"84510fe7-22c3-4786-8c52-cafd5e0e2f69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Using cached wandb-0.16.1-py3-none-any.whl (2.1 MB)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Using cached GitPython-3.1.40-py3-none-any.whl (190 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Using cached sentry_sdk-1.39.1-py2.py3-none-any.whl (254 kB)\n","Collecting docker-pycreds>=0.4.0 (from wandb)\n","  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting setproctitle (from wandb)\n","  Using cached setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.39.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.1\n"]}],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbxDbiU2bZh_","executionInfo":{"status":"ok","timestamp":1703145591449,"user_tz":-540,"elapsed":13882,"user":{"displayName":"정의양","userId":"12576123445162133975"}},"outputId":"07781ee1-2bad-4e88-fa2d-b71122694e83"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!wandb login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dz-4I5TEb8Ns"},"outputs":[],"source":["import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLUXzU4Q7rWR"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"klHSJT4x1hQ6"},"outputs":[],"source":["class CNN(nn.Module):\n","  def __init__(self):\n","    super(CNN,self).__init__()\n","    #convolution\n","    self.conv1=nn.Conv2d(in_channels=3,out_channels=32,kernel_size=(3,3),padding=1)\n","    self.conv2=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=(3,3),padding=1)\n","    #pooling\n","    self.pool=nn.MaxPool2d(kernel_size=(2,2))\n","\n","    self.fc1=nn.Linear(64*7*7,128)\n","    self.fc2=nn.Linear(128,10)\n","\n","  def forward(self,x):\n","    # 각자 합성곱, 활성함수, pooling 적용\n","    x=self.pool(F.relu(self.conv1(x)))\n","    x=self.pool(F.relu(self.conv2(x)))\n","    x=x.view(-1,64*7*7)\n","    x=F.relu(self.fc1(x))\n","    x=self.fc2(x)\n","\n","    return F.softmax(x,dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J5echdEc4exp"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# 앞서 정의한 모델을 장치로 올림, 모델 정의\n","model = CNN().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGXztFmWUo_S"},"outputs":[],"source":["import torch.optim as optim\n","\n","# 모델 학습을 위한 손실 함수와 최적화 함수\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"DHrJvO92ZsPm","executionInfo":{"status":"ok","timestamp":1703145605690,"user_tz":-540,"elapsed":9,"user":{"displayName":"정의양","userId":"12576123445162133975"}},"outputId":"85ecec74-fbfd-4506-e7e4-31dbc66bf0fd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nimport zipfile\\nzipfile.ZipFile('drive/My Drive/openAI/data/data.zip').extractall('drive/My Drive/openAI/data')\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["# 압축 풀기용 코드 한번만 실행\n","'''\n","import zipfile\n","zipfile.ZipFile('drive/My Drive/openAI/data/data.zip').extractall('drive/My Drive/openAI/data')\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uf208mknKx2W"},"outputs":[],"source":["import os\n","import random\n","from PIL import Image, UnidentifiedImageError,ImageFile"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"RPK1weZX8RsT","executionInfo":{"status":"ok","timestamp":1703145605690,"user_tz":-540,"elapsed":7,"user":{"displayName":"정의양","userId":"12576123445162133975"}},"outputId":"0cbd0c8c-c95d-4433-9c19-987dfdaccbdf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ndef validate_image(filepath):\\n    try:\\n        img = Image.open(filepath).convert('RGB')\\n        img.load()\\n    except UnidentifiedImageError:\\n        print(f'Corrupted Image is found at: {filepath}')\\n        return False\\n    except (IOError, OSError):\\n        print(f'Truncated Image is found at: {filepath}')\\n        return False\\n    else:\\n        return True\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["# 원본 이미지 검증\n","'''\n","def validate_image(filepath):\n","    try:\n","        img = Image.open(filepath).convert('RGB')\n","        img.load()\n","    except UnidentifiedImageError:\n","        print(f'Corrupted Image is found at: {filepath}')\n","        return False\n","    except (IOError, OSError):\n","        print(f'Truncated Image is found at: {filepath}')\n","        return False\n","    else:\n","        return True\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"_oy9aUXlfsHK","executionInfo":{"status":"ok","timestamp":1703145605690,"user_tz":-540,"elapsed":6,"user":{"displayName":"정의양","userId":"12576123445162133975"}},"outputId":"6f6fd374-61c8-4ffc-8a20-a5cdb0bece35"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nroot = 'drive/My Drive/openAI/data/유증상_라벨_검증'\\n\\ndirs = os.listdir(root)\\n\\nfor dir_ in dirs:\\n    folder_path = os.path.join(root, dir_)\\n    files = os.listdir(folder_path)\\n\\n    for file_name in files:\\n        file_path = os.path.join(folder_path, file_name)\\n\\n        # 파일 확장자 확인\\n        _, file_extension = os.path.splitext(file_name)\\n\\n        if file_extension.lower() == '.jpg':\\n            valid = validate_image(file_path)\\n            if not valid:\\n                # 오류가 있는 이미지 파일 삭제\\n                os.remove(file_path)\\n        elif file_extension.lower() == '.json':\\n            # JSON 파일은 삭제하지 않음\\n            pass\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["# 이미지 검증\n","'''\n","root = 'drive/My Drive/openAI/data/유증상_라벨_검증'\n","\n","dirs = os.listdir(root)\n","\n","for dir_ in dirs:\n","    folder_path = os.path.join(root, dir_)\n","    files = os.listdir(folder_path)\n","\n","    for file_name in files:\n","        file_path = os.path.join(folder_path, file_name)\n","\n","        # 파일 확장자 확인\n","        _, file_extension = os.path.splitext(file_name)\n","\n","        if file_extension.lower() == '.jpg':\n","            valid = validate_image(file_path)\n","            if not valid:\n","                # 오류가 있는 이미지 파일 삭제\n","                os.remove(file_path)\n","        elif file_extension.lower() == '.json':\n","            # JSON 파일은 삭제하지 않음\n","            pass\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VDFCkR6B07gP"},"outputs":[],"source":["# json 파일에서 뽑아 사용하는 경우\n","import torch\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import json\n","class MyDataLoader(Dataset):\n","    def __init__(self, root_folder, batch_size, transform):\n","        self.root_folder = root_folder\n","        self.transform = transform\n","        self.batch_size = batch_size\n","        self.data = self.load_data()\n","\n","    def load_data(self):\n","        data = []\n","\n","        for root, dirs, files in os.walk(self.root_folder):\n","            for filename in files:\n","                if filename.endswith('.jpg'):\n","                    img_path = os.path.join(root, filename)\n","\n","                    json_filename = os.path.splitext(filename)[0] + '.json'\n","                    json_file_path = os.path.join(root, json_filename)\n","\n","                    if not os.path.exists(json_file_path):\n","                        continue\n","\n","                    with open(json_file_path, 'r') as json_file:\n","                        metadata = json.load(json_file)\n","\n","                    label = metadata['metaData']['lesions']\n","                    data.append((img_path, label))\n","\n","        return data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def label_convert(self,label):\n","        label_mapping = {\"A2\": 0, \"A3\": 1, \"A4\": 2, \"A5\": 3, \"A6\": 4}\n","        return label_mapping.get(label,-1)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.data[idx]\n","        image = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        label=self.label_convert(label)\n","\n","        return image, label\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xeERNd2XDqu7"},"outputs":[],"source":["#이미지 데이터 가져오기\n","from torchvision import transforms\n","'''\n","#데이터 위치 지정\n","train_data = torchvision.datasets.ImageFolder(\n","    root = 'drive/My Drive/openAI/data/유증상_라벨_학습',\n","    transform= transforms.Compose([\n","      # 사이즈가 너무 커서 세션 다운되므로 줄임\n","      transforms.Resize([28,28]),\n","      # dataloader가 PIL 이미지를 수신하기 위해 이미지의 변형이 필요\n","      transforms.ToTensor()\n","    ])\n",")\n","test_data= torchvision.datasets.ImageFolder(\n","    root = 'drive/My Drive/openAI/data/유증상_라벨_검증',\n","    transform= transforms.Compose([\n","      transforms.Resize([28,28]),\n","      transforms.ToTensor()\n","    ])\n",")\n","print(train_data)\n","print(test_data)\n","\n","#데이터를 배치 사이즈에 맞게 가져오기\n","#배치 사이즈=100\n","\n","train_loader=MyDataLoader(train_data,batch_size=100)\n","test_loader=MyDataLoader(test_data,batch_size=100)\n","'''\n","\n","train_root='drive/My Drive/openAI/data/유증상_라벨_학습'\n","test_root= 'drive/My Drive/openAI/data/유증상_라벨_검증'\n","\n","transform=transforms.Compose([\n","    transforms.Resize([28, 28]),\n","    transforms.ToTensor()\n","])\n","\n","train_loader = MyDataLoader(train_root, batch_size=100, transform=transform)\n","\n","test_loader = MyDataLoader(test_root, batch_size=100, transform=transform)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKEeMvJ0wL6h","executionInfo":{"status":"ok","timestamp":1703151751763,"user_tz":-540,"elapsed":15846,"user":{"displayName":"송지윤","userId":"18012978256885165057"}},"outputId":"6c4ce220-5809-40f4-d08e-0d9619e4e469"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_az6EghsMBxJ","executionInfo":{"status":"ok","timestamp":1703146133669,"user_tz":-540,"elapsed":461,"user":{"displayName":"정의양","userId":"12576123445162133975"}},"outputId":"276ca157-f64d-40ff-f123-a49b24586f73"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0.8980, 0.8941, 0.8824,  ..., 0.3176, 0.2588, 0.2863],\n","         [0.8745, 0.8784, 0.8667,  ..., 0.6706, 0.4510, 0.3333],\n","         [0.8510, 0.8471, 0.8431,  ..., 0.8784, 0.8078, 0.6353],\n","         ...,\n","         [0.4980, 0.4902, 0.4784,  ..., 0.7255, 0.7725, 0.7412],\n","         [0.4980, 0.4784, 0.4588,  ..., 0.7020, 0.7608, 0.7451],\n","         [0.4706, 0.4510, 0.4314,  ..., 0.6353, 0.7529, 0.7608]],\n","\n","        [[0.9020, 0.8902, 0.8706,  ..., 0.2118, 0.1373, 0.1255],\n","         [0.8667, 0.8667, 0.8549,  ..., 0.6353, 0.3725, 0.1686],\n","         [0.8314, 0.8235, 0.8196,  ..., 0.8902, 0.8078, 0.5882],\n","         ...,\n","         [0.4902, 0.4784, 0.4667,  ..., 0.7216, 0.7725, 0.7412],\n","         [0.4824, 0.4627, 0.4431,  ..., 0.6824, 0.7451, 0.7412],\n","         [0.4510, 0.4314, 0.4078,  ..., 0.5804, 0.7176, 0.7490]],\n","\n","        [[0.8824, 0.8706, 0.8510,  ..., 0.1490, 0.0706, 0.0431],\n","         [0.8549, 0.8510, 0.8353,  ..., 0.6000, 0.3255, 0.0784],\n","         [0.8157, 0.8039, 0.7961,  ..., 0.8745, 0.7922, 0.5451],\n","         ...,\n","         [0.4706, 0.4549, 0.4392,  ..., 0.7137, 0.7647, 0.7333],\n","         [0.4588, 0.4353, 0.4196,  ..., 0.6706, 0.7412, 0.7333],\n","         [0.4235, 0.4039, 0.3765,  ..., 0.5412, 0.7020, 0.7412]]])\n","0\n"]}],"source":["print(train_loader[0][0])\n","print(train_loader[0][1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"S39fuQsUbNHC","executionInfo":{"status":"ok","timestamp":1703146138371,"user_tz":-540,"elapsed":4703,"user":{"displayName":"정의양","userId":"12576123445162133975"}},"outputId":"afdad4e9-6ea5-4d49-dfff-70dc8519e514"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meuiyang2000\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20231221_080858-f7vv81qr</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/euiyang2000/openSourceAI/runs/f7vv81qr' target=\"_blank\">CNN</a></strong> to <a href='https://wandb.ai/euiyang2000/openSourceAI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/euiyang2000/openSourceAI' target=\"_blank\">https://wandb.ai/euiyang2000/openSourceAI</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/euiyang2000/openSourceAI/runs/f7vv81qr' target=\"_blank\">https://wandb.ai/euiyang2000/openSourceAI/runs/f7vv81qr</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/euiyang2000/openSourceAI/runs/f7vv81qr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7eb623c74310>"]},"metadata":{},"execution_count":15}],"source":["wandb.init(project='openSourceAI',name='CNN')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"sioFg-AIdfId","executionInfo":{"status":"error","timestamp":1703146300899,"user_tz":-540,"elapsed":313,"user":{"displayName":"정의양","userId":"12576123445162133975"}},"outputId":"fc7a15ce-195b-46bc-e1cb-205e77d1da60"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-50b2bcf4bf72>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0;31m# Zero the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'to'"]}],"source":["#학습\n","for epoch in range(5):\n","  model.train()\n","  running_loss = 0.0\n","  correct = 0\n","  total = 0\n","  for i, data in enumerate(train_loader, 0):\n","      # Get the inputs; data is a list of [inputs, labels]\n","      #label 데이터 추출 후 담기\n","      inputs, labels= data\n","\n","      if isinstance(labels, str):\n","        labels = torch.tensor([int(labels)]).to(device)\n","\n","      inputs, labels= inputs.to(device), labels.to(device)\n","\n","      # Zero the parameter gradients\n","      optimizer.zero_grad()\n","\n","      # Forward pass\n","      outputs = model(inputs)\n","\n","      # Compute the loss\n","      loss = criterion(outputs, labels)\n","\n","      # Backward pass and optimize\n","      loss.backward()\n","      optimizer.step()\n","\n","      # Accuracy\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += labels.size(0)\n","      correct += (predicted == labels).sum().item()\n","\n","      # log loss\n","      wandb.log({'train/loss':loss.item(), 'train/acc':correct/total})\n","\n","      # Print statistics\n","      running_loss += loss.item()\n","      if i % 100 == 99:    # Print every 100 mini-batches\n","          print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n","          running_loss = 0.0\n","\n","  model.eval()\n","  with torch.no_grad():\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for i, data in enumerate(test_loader, 0):\n","      #label 데이터 추출 후 담기\n","      inputs, labels= data\n","\n","      if isinstance(labels, str):\n","        labels = torch.tensor([int(labels)]).to(device)\n","\n","      inputs, labels= inputs.to(device), labels.to(device)\n","\n","      # Forward pass\n","      outputs = model(inputs)\n","\n","      # Compute the loss\n","      loss = criterion(outputs, labels)\n","\n","      # Accuracy\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += labels.size(0)\n","      correct += (predicted == labels).sum().item()\n","      running_loss += loss.item()\n","\n","      # log loss\n","      wandb.log({'test/loss':loss.item(), 'test/acc':correct/total})\n","\n","      # Print statistics\n","      running_loss += loss.item()\n","      if i % 100 == 99:    # Print every 100 mini-batches\n","          print(f'Test Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n","          running_loss = 0.0\n","\n","\n","print('Finished Training')\n","wandb.finish()"]},{"cell_type":"code","source":["# 배치정규화 CNN\n","class CNN(nn.Module):\n","  def __init__(self):\n","      super(CNN, self).__init__()\n","      self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1)\n","      self.bn1 = nn.BatchNorm2d(32)\n","      self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n","      self.bn2 = nn.BatchNorm2d(64)\n","      self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n","      self.fc1 = nn.Linear(64 * 7 * 7, 128)\n","      self.fc2 = nn.Linear(128, 10)\n","\n","  def forward(self,x):\n","    # 각자 합성곱, 활성함수, pooling 적용\n","    x=self.pool(F.relu(self.conv1(x)))\n","    x=self.pool(F.relu(self.conv2(x)))\n","    x=x.view(-1,64*7*7)\n","    x=F.relu(self.fc1(x))\n","    x=self.fc2(x)\n","\n","    return F.softmax(x,dim=1)"],"metadata":{"id":"tFMVcMYc9JVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 배치정규화+드롭아웃 CNN\n","class CNN(nn.Module):\n","  def __init__(self):\n","      super(CNN, self).__init__()\n","      self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1)\n","      self.bn1 = nn.BatchNorm2d(32)\n","      self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n","      self.bn2 = nn.BatchNorm2d(64)\n","      self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n","      self.fc1 = nn.Linear(64 * 7 * 7, 128)\n","      self.dropout = nn.Dropout(0.5)\n","      self.fc2 = nn.Linear(128, 10)\n","\n","  def forward(self,x):\n","    # 각자 합성곱, 활성함수, pooling 적용\n","    x=self.pool(F.relu(self.conv1(x)))\n","    x=self.pool(F.relu(self.conv2(x)))\n","    x=x.view(-1,64*7*7)\n","    x=F.relu(self.fc1(x))\n","    x=self.fc2(x)\n","\n","    return F.softmax(x,dim=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"Qgr1BJHg--6K","executionInfo":{"status":"error","timestamp":1703239532848,"user_tz":-540,"elapsed":4,"user":{"displayName":"송지윤","userId":"18012978256885165057"}},"outputId":"b175ef3d-feee-4e24-af67-267b4e9f74d2"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-31a289fa2169>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 배치정규화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NMsyTKCG_JFq"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}